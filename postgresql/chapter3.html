<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Postgresql Optimization</title>
</head>
<body>
    <h3>Chapter 3: (Even More Theory: Algorithms)</h3>
    <b>Algorithm cost model</b>
    <br/>
    <p>
        for choosing the best query we need some metrics to show selected Algorithm
        is appropriate for our query.
        there is two main factors:
        <ol>
            <li>cpu cycles</li>
            <li>i/o access</li>
        </ol>
        combination of these metrics is cost function
    </p>
    <b>Storage structure</b>
    <br/>
    <p>
        any file use in database is divided into blocks of the same length. postgresql uses 8192 bytes block.
        a block is the unit which is transfered between hard drive and main memory.

        the number of i/o access is the number of blocks that we want to read.
    </p>
    <p>here is view of database storage structure</p>
    <img src="./images/stirage.PNG" />
    <p>
        The allocation of items to blocks also depends on the type of the
        database object. Table rows are stored using a data structure called a heap: a
        row can be inserted in any block that has sufficient free space, without any
        specific ordering. Other objects (e.g., indexes) may use blocks differently.
    </p>
    <h2>diffrent types of access </h2>
    <ol>
        <li>full scan</li>
        <li>index-based table access</li>
        <li>index-only scan</li>
    </ol>
    <h3>FULL SCAN</h3>
    <p>
        in full scan database engine reads all data from disk and apply filters.
        here is s simplae pseudocode for this operation
        <pre>
            FOR each block IN a_table LOOP
                read block;
                FOR each row IN block LOOP
                    IF filter_condition (row)
                    THEN output (row)
                    END IF;
                END LOOP;
            END LOOP;
        </pre>
    </p>
    <h3>Index-Based table access</h3>
    <p>
        PostgreSQL allows for building additional, redundant data structures, making
        data access dramatically faster than a simple sequential read.These additional structures are called indexes.
    </p>
    <p>
        indexes provide additional data access paths. they allow us to
        determine what values are stored in the rows of a table without actually
        reading the tableâ€”this is how index-based access works
    </p>
    <p>
        The algorithm extracts a list of pointers to blocks that contain rows with values satisfying
        the filtering condition, and only these blocks are read from the table
    </p>
    <p>
        To get a table row from a pointer, the block containing this row must be read
    </p>
    <p>
        Note: for small values of selectivity, most likely, all rows
        satisfying the filtering conditions will be located in different blocks and,
        consequently, the cost is proportional to the number of result rows. For
        larger values of selectivity, the number of processed blocks approaches the
        total number of blocks. In the latter case, the cost becomes higher than the
        cost of a full scan because resources are needed to access the index.
    </p>
    <h3>Index-Only scan</h3>
    <p>
        Data access operations do not necessarily return entire rows. If some
        columns are not needed for the query, these columns can be skipped as soon
        as a row passes filtering conditions (if any). More formally, this means that
        the logical project operation is combined with data access. This combination
        is especially useful if an index used for filtering contains all columns that are
        needed for the query
    </p>

<hr/>
    <p>The choice of the best data access algorithm depends mostly on query
        selectivity.</p>
        <img src="./images/DataAccessComparison.PNG" width="200px" />

<hr/>
    <h3>index structure</h3>
    <p>indexes are redundant data that stores some pointers to actual datas.
        it effects on performance for fetching data but is essential to know that it slow down modification(insert,update,delete) operations.
        there is diffrent data structures behind indexes.
        here is a picture that shows how index work
    </p>
    <img src="./images/index.PNG" />
    <hr/>
    <h3>B-Trees</h3>
    <p>
        The most common structure of an index is a B-tree. The structure of a B-tree is shown in following picture
    </p>
    <img src="./images/btree.PNG" />
    <hr/>
    <h3>Bitmaps</h3>
    <p>
        A bitmap is an auxiliary data structure that is used internally in PostgreSQL for several different purposes.
        Usually a bitmap contains one bit for each block (8192 bytes). The value
        of the bit is 1 if the block has a property and 0 if it hasn't. following image shows
        how bitmaps are used to access data through multiple indexes
    </p>
    <img src="./images/bitmap.PNG" />
    <p>
        there is other kind of indexes like hash indexes which is good for equal operator and r-tree for spatial conditions.
        we will talk about them in later chapters.
    </p>
    <hr/>
    <h2>
        Combining Relations
    </h2>
    <p>
        There is diffrent combining relations algorithms.
    </p>
    <ul>
        <li>Nested Loops</li>
        <li>Hash-Based Algorithms</li>
    </ul>
    <hr/>
    <h3>Nested Loops</h3>
    <p>
        pseudo code:
        <pre>
            FOR row1 IN table1 LOOP
                FOR row2 IN table2 LOOP
                    IF match(row1,row2) THEN
                        INSERT output row
                    END IF
                END LOOP
            END LOOP
        </pre>
        <img src="./images/nested.PNG" />
    </p>
    <hr/>
    <h3>Hash-Based Algorithms</h3>
    <p>
        The output of a natural join consists of pairs of rows from R and S that have
        equal values on the join attributes. The idea of the hash join algorithm is
        simple: if the values are equal, then the hash values are also equal.
    </p>
    <img src="./images/hash.PNG" />
    <p>The basic version of the hash join algorithm includes two phases :</p>
    <ol>
        <li>During the build phase, all tuples of R are stored in buckets according to
            the values of the hash function.</li>
            <li>
                In the probe phase, each row of table S is sent to an appropriate bucket.
If matching rows of table R are in the bucket, output rows are produced.
            </li>
    </ol>
    <hr/>
    <h3>Sort-Merge Algorithm</h3>
    <img src="./images/sort-merge.PNG" />
    <p>
        The first phase of the algorithm sorts both input tables in ascending
        order by the join attribute.
        When the input tables are properly ordered, the merge phase scans both
        input tables once
    </p>
    <hr/>
    <h2>Comparing Algorithms</h2>
    <p>
        Any of the algorithms can be the best, depending on the circumstances. The
        nested loop algorithm is more universal and is the best for small index-based
        joins; a sort-merge and hash are more efficient for large tables, when
        applicable.
    </p>
</body>
</html>